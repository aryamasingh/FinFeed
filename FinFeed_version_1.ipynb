{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 175,
=======
   "execution_count": 29,
>>>>>>> 21f546a33efce32c38c7cf6f95e6d816bb6afd70
   "id": "e9cf0832-9171-4918-9e53-723b8e883481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from pinecone import Pinecone,  PodSpec\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
<<<<<<< HEAD
    "import re\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from transformers import pipeline\n",
    "load_dotenv(\"API_KEYS\")\n",
=======
>>>>>>> 21f546a33efce32c38c7cf6f95e6d816bb6afd70
    "class FinFeedRAG:\n",
    "    def __init__(self, pine_cone_api_key, openai_api_key, pinecone_index, embeddings_model= OpenAIEmbeddings(),model='gpt-3.5-turbo'):\n",
    "        self.openai_api_key=openai_api_key\n",
    "        self.api_key_pinecone = pine_cone_api_key\n",
    "        self.pinecone_index = pinecone_index\n",
    "        # Initialize Pinecone connection\n",
    "        self.vector_db = None\n",
    "        self.embeddings=embeddings_model\n",
    "        self.model=model\n",
    "        self.template = \"\"\"\n",
<<<<<<< HEAD
    "                Answer the question based on the context below but pretend like you are a news reporter who just received the context as the latest news. \n",
    "                If you can't answer the question, reply \"I do not have enough information to answer this question\".\n",
=======
    "                Answer the question based on the context below. If you can't\n",
    "                answer the question, reply \"I don't know\".\n",
>>>>>>> 21f546a33efce32c38c7cf6f95e6d816bb6afd70
    "                \n",
    "                Context: {context}\n",
    "                \n",
    "                Question: {question}\n",
    "                \"\"\"\n",
    "\n",
    "    def initialize_pinecone(self):\n",
    "        if self.vector_db is None:  # Check if it's already initialized\n",
    "            pc = Pinecone(api_key=self.api_key_pinecone)\n",
    "            self.vector_db = pc.Index(self.pinecone_index)  # Connect to the index and store the connection\n",
<<<<<<< HEAD
    "        return self.vector_db\n",
    "        \n",
    "    \n",
    "    def preprocess_youtube_text(self, text_file, chunksize,chunkoverlap):\n",
    "\n",
    "        self.preprocess_input(text_file,save_back_to_file=True)\n",
    "        \n",
=======
    "        return self\n",
    "    \n",
    "    def preprocess_youtube_text(self, text_file, chunksize,chunkoverlap):\n",
>>>>>>> 21f546a33efce32c38c7cf6f95e6d816bb6afd70
    "        loader = TextLoader(text_file) #text instance of langchain\n",
    "        text_documents = loader.load() \n",
    "        # Assuming RecursiveCharacterTextSplitter is a class you have access to or have created\n",
    "        splitter = RecursiveCharacterTextSplitter(chunk_size=chunksize, chunk_overlap=chunkoverlap)\n",
<<<<<<< HEAD
    "        processed_text = splitter.split_documents(text_documents)\n",
    "        # Further processing can be done here if necessary\n",
    "        return processed_text\n",
    "\n",
    "    def upload_to_vb(self,text,embeddings,chunksize, chunkoverlap,index=None):\n",
    "        if index is None:\n",
    "            index = self.pinecone_index\n",
    "        return PineconeVectorStore.from_documents(self.preprocess_youtube_text(text,chunksize,chunkoverlap), self.embeddings, index_name=index)     \n",
    "\n",
    "\n",
    "    def preprocess_input(self, text_file,save_back_to_file=True):\n",
    "        # Simple text preprocessing: lowercasing, removing punctuation need to add more preprocessing steps do research on it\n",
    "        # Read and process the content and rewrite it\n",
    "        if save_back_to_file==True:\n",
    "            with open(text_file, 'r') as file:\n",
    "                # Read the contents of the file\n",
    "                text = file.read()\n",
    "            processed_text = text.lower()\n",
    "            processed_text = re.sub(r'[^\\w\\s]', '', processed_text)\n",
    "            tokens = word_tokenize(processed_text)\n",
    "            filtered_words = [word for word in tokens if word.lower() not in stopwords.words('english')]\n",
    "            # Join words back into a single string\n",
    "            final_text = ' '.join(filtered_words)\n",
    "            # Write the processed content back, replacing the original\n",
    "            with open(text_file, 'w') as file:\n",
    "                file.write(final_text)\n",
    "        else:\n",
    "            with open(text_file, 'r') as file:\n",
    "                # Read the contents of the file\n",
    "                text = file.read()\n",
    "            processed_text = text.lower()\n",
    "            processed_text = re.sub(r'[^\\w\\s]', '', processed_text)\n",
    "            tokens = word_tokenize(processed_text)\n",
    "            filtered_words = [word for word in tokens if word.lower() not in stopwords.words('english')]\n",
    "            # Join words back into a single string\n",
    "            final_text = ' '.join(filtered_words)\n",
    "            return final_text\n",
    "        \n",
    "           \n",
    "\n",
    "    def most_common(self, input_text_file,most_common=10):\n",
    "        # Preprocess the text\n",
    "        processed_text = self.preprocess_input(input_text_file,save_back_to_file=False)    \n",
    "        # Extract keywords based on frequency, assuming more frequent terms are more relevant\n",
    "        words = processed_text.split()\n",
    "        word_freq = Counter(words)\n",
    "        common_words = word_freq.most_common(most_common)  # Get the top 5 words       \n",
=======
    "        processed_text = splitter.split(text_documents)\n",
    "        # Further processing can be done here if necessary\n",
    "        return processed_text\n",
    "\n",
    "    def upload_to_vb(self,text,embeddings,index=None):\n",
    "        if index is None:\n",
    "            index = self.pinecone_index\n",
    "        return PineconeVectorStore.from_documents(self.preprocess_youtube_text(text), self.embeddings, index_name=index)     \n",
    "\n",
    "\n",
    "    def preprocess_user_input(self, text):\n",
    "        # Simple text preprocessing: lowercasing, removing punctuation\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        return text\n",
    "\n",
    "    def generate_query(self, input_text):\n",
    "        # Preprocess the text\n",
    "        processed_text = self.preprocess_user_input(input_text)    \n",
    "        # Extract keywords based on frequency, assuming more frequent terms are more relevant\n",
    "        words = processed_text.split()\n",
    "        word_freq = Counter(words)\n",
    "        common_words = word_freq.most_common(5)  # Get the top 5 words       \n",
>>>>>>> 21f546a33efce32c38c7cf6f95e6d816bb6afd70
    "        # Form a query by joining the most common words\n",
    "        query = ' '.join(word for word, _ in common_words)\n",
    "        return query\n",
    "\n",
    "     \n",
    "    def retrieve_embeddings(self, query, most_similar=2):\n",
    "        assert self.vector_db is not None, \"Initialize Pinecone first\"\n",
    "        query_result = self.vector_db.query(vector=self.embeddings.embed_query(query), top_k=most_similar)\n",
    "        ids = [item['id'] for item in query_result['matches']]\n",
    "        return [self.vector_db.fetch(ids)['vectors'][id]['values'] for id in ids]\n",
    "\n",
    "\n",
    "    def query_langchain(self, query, most_similar=2,index=None):\n",
    "        if index is None:\n",
    "            index = self.pinecone_index\n",
    "        # Use LangChain to process the query and get results\n",
    "        return PineconeVectorStore.from_existing_index(index_name=self.pinecone_index,embedding=self.embeddings).similarity_search(query,k=most_similar)\n",
    "        \n",
    "\n",
    "    def provide_context(self, query,index=None,most_similar=2):\n",
    "        if index is None:\n",
    "            index = self.pinecone_index\n",
    "        # Provide context to LLM\n",
    "        return PineconeVectorStore.from_existing_index(index_name=index,embedding=self.embeddings).as_retriever(search_type='similarity',\n",
    "                search_kwargs={\n",
    "                'k': most_similar}).invoke(query)\n",
    "        \n",
    "    def prompt(self,template=None):\n",
    "        if template is None:\n",
    "            template = self.template\n",
    "        return ChatPromptTemplate.from_template(template)\n",
    "        \n",
    "    def llm(self,model=None):\n",
    "        if model is None:\n",
    "            model = self.model\n",
    "        return ChatOpenAI(openai_api_key=self.openai_api_key, model=model)\n",
    "        \n",
    "    def parser(self):\n",
    "        return StrOutputParser()\n",
    "\n",
    "    def chain(self,query):\n",
    "        #complete_query = self.prompt().format(context=self.provide_context(query),question=query)\n",
    "        #response = self.llm().invoke(complete_query)\n",
    "        #return self.parser().invoke(response)\n",
    "        chaining = (\n",
    "        {\"context\": PineconeVectorStore.from_existing_index(index_name=self.pinecone_index,embedding=self.embeddings).as_retriever(search_type='similarity',\n",
    "                search_kwargs={\n",
<<<<<<< HEAD
    "                'k': 10}), \n",
=======
    "                'k': 4}), \n",
>>>>>>> 21f546a33efce32c38c7cf6f95e6d816bb6afd70
    "         \"question\": RunnablePassthrough()}\n",
    "        | self.prompt()\n",
    "        | self.llm()\n",
    "        | self.parser())\n",
    "        return chaining.invoke(query)\n",
<<<<<<< HEAD
    "    def pipe(self,chunk):\n",
    "        pipe = pipeline(\"text-classification\", model=\"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\")\n",
    "        return pipe(chunk)\n",
    "\n",
    "    def get_sentiment(self,chunks,neutrality_threshdold=0.3):\n",
    "        \"\"\"Gets the compound sentiment of the chunks based on their individual sentiment\n",
    "        Parameters\n",
    "        ----------\n",
    "        chunks : list\n",
    "            List of text chunks\n",
    "        neutrality_threshdold : float, optional\n",
    "            A hyperparameter neutrality_threshdold tunes how certain we need to be of a sentiment to classify it as positive or negative\n",
    "            (If neutrality_threshdold=1, any list of chunks will result in a neutral sentiment\n",
    "            If neutrality_threshdold=0, any list of chunks will be classified as positive or negative)\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            1 for positive, 0 for neutral, and -1 for negative\n",
    "        \"\"\"\n",
    "        #Assing a numerical value to each sentiment to simplify calculations\n",
    "        sentiment_values = {'positive':1, 'neutral':0, 'negative':-1}\n",
    "        #Run each chunk through sentiment model\n",
    "        sentiments = [self.pipe(chunk.page_content)[0] for chunk in chunks]\n",
    "        #Print out model output\n",
    "        #print(sentiments)\n",
    "        #For each chunk, we compute a sentiment score by multiplying the score times the sentiment value corresponding to its label\n",
    "        sentiment_scores = [(sentiment['score'])*sentiment_values[sentiment['label']] for sentiment in sentiments]\n",
    "        #Average sentiment_scores\n",
    "        avg_sentiment_score = sum(sentiment_scores)/len(sentiment_scores)\n",
    "        if avg_sentiment_score >= neutrality_threshdold:\n",
    "            return ('positive',sentiments)\n",
    "        elif avg_sentiment_score <= -neutrality_threshdold:\n",
    "            return ('negative',sentiments)\n",
    "        else:\n",
    "            return ('neutral',sentiments)\n",
    "            \n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f9810625-161c-43af-988f-2324f3400c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pine = bot.initialize_pinecone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bda6785f-59af-43de-8e3e-fa56054c2c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 1022}},\n",
       " 'total_vector_count': 1022}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pine.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "45d36734-4bb9-43ac-9ddf-390ccffdeeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot = FinFeedRAG(pine_cone_api_key=os.getenv('PINECONE_API_KEY'), openai_api_key=os.getenv('OPENAI_API_KEY'), pinecone_index='day1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "bf8b70d2-6e12-43b9-a267-e4d74e78e889",
   "metadata": {},
   "outputs": [],
   "source": [
    "list = [\"text/inflation_fears,_richemont's_new_'bos'__bloomberg_markets_today_0517.txt\",\"text/stocks_tread_water_with_dow_aiming_for_40,000__may_17_yahoo_finance.txt\",\"text/bloomberg_markets_asia_05172024.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7b099724-9e1a-462f-99c2-38870be9cd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "for new in list:\n",
    "\n",
    "    bot.upload_to_vb(new,embeddings=OpenAIEmbeddings(),chunksize=200,chunkoverlap=20,index='day1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "1b60578b-bf8f-473b-b10f-0063526ed0f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"1. Inflationary forces are a major concern for the US economy, with a list of green economy initiatives, remonetization, infrastructure spending, trade disputes, and large fiscal deficits contributing to the challenges.\\n2. President Biden's administration unveiled sweeping tariff hikes on a range of Chinese imports, leading to criticism from the International Monetary Fund for aggressive moves.\\n3. The US economy is experiencing a bit of a pullback in inflation impact, indicating a potential shift towards a K-shaped economy with strong growth.\\n4. Consumption by consumers is crucial to keeping the economy on track, with retail sales performance being a key indicator of economic health.\\n5. The US economy is facing challenges with the disappearance of banks and the need for interesting opportunities in sectors like oil, gas, and banking.\\n6. The impact of tariffs on the economy is being discussed, with a focus on changing economic outcomes and national security implications.\\n7. The possibility of worsening economic conditions is looming, as evidenced by the potential damage to stocks and the effects of high interest rates.\\n8. The US economy is powered by domestic consumption and investment, while China is utilizing its playbook to drive economic recovery through exports.\\n9. There are concerns about higher inflation and unusual adjustments in the economy, with the need for consumers to do heavy lifting to maintain economic growth.\\n10. President Biden's top economic priorities are driving economic policies, with a focus on navigating through a changing economic landscape.\""
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot.chain(\"Give me 10 bullets points affecting US economy and World economy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "dd899b9d-9022-4c39-82a4-68ef3f8a7931",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot.provide_context(\"Give me 10 bullet points about US stock market and worldwide\",most_similar=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1204b228-176c-4dec-ba1f-56f4c33b7244",
   "metadata": {},
   "outputs": [],
   "source": []
=======
    "     "
   ]
>>>>>>> 21f546a33efce32c38c7cf6f95e6d816bb6afd70
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
