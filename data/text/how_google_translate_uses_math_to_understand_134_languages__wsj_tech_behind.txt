fraction second google translate make sense surroundings isnt google translate early 2000s past two decades technology gone complete overhaul shifting basic pattern matching tool sophisticated neural network handles 130 languages works turning language something computers understand math exciting times people like language math tech behind google translate theres little code left today early days phrasebased translation shut deleted almost google translate two decades ago laid foundation use today launched 2006 worked playing matching game first model looked lots examples professional translations scraped internet users entered sentences translation tool would break longest possible chunks words seen combine chunks uses much sophisticated machine learning approach socalled transformer model building block modern ai transformers turn language math assigning numbers words key insight series numbers represent meaning math vectors show something relationships meanings words language google translate supports every word gets converted vector written like list numbers way computer math instance king minus man plus woman equals queen specific numbers assigned word dont really matter theyre different different languages matters word relates every word based machine learning billions examples time want translate something individual word computer also figure words work together transformers breakthrough machine learning come next generation neural translation called transformer architecture added level moved representing meaning one word row numbers putting meanings words table math whole table enables math talks meaning word importance relationships words say youre trying translate italian sign english first google translate would turn word vector vectors would put one giant table matrix computer tries figure word interacts every word side mathematically basically lot multiplication important kind magical step laying matrix whats called matrix multiplication enough solve problem creates new list numbers whats called context vector something pretty special list numbers actually represents sentence means sum words least model done job correctly put together clever people invented transformers train lot data eventually get collection numbers meaningfully represents meaning sentence thats called encoder stage decoder roughly speaking encoder reverse computer decode back human language decoder also goes lots lots operations finally start getting vectors mapped back individual words hopefully get closed holiday language becomes math getting math work requires lot training lots numbers math problem chosen randomly refined computer learns billions examples deploying update set values weights engineers run numerous tests ai evaluator professional human translators check accuracy since every possible combination words leads unique equation impossible test everything since model trained translations going english often requires steps go two nonenglish languages example want translate something japanese zulu go japanese english english zulu first thing happens use google ar translate actually extract text image see detects chinese translates english makes information lot accessible many people typing script foreign language option key component technology called optical character recognition ocr google using since 2002 started digitizing libraries google books initially would something simple like pattern matching think yes b whatnot optical character recognition also uses transformers first google lens identifies lines text text direction determines specific characters words instead dividing sentence words assigning numbers word though divides image patches pixels called tokens encoder transformer going process tokens simultaneously predict best character best word eventually means google lens companys visual search tool often read things even cant make every single letter transformers theyre able pick grammar spending mistake transformer also able use context disambiguate still extract right word completes optical character recognition google lens analyzes layout text thats computer would know translate sign matter dont give rather dont matter give look newspaper humans excellent glancing understanding reading order read first concept isnt actually easy solve technically hard key optical character recognition understand something meaning reading also done extensive training chunks text sent translator google lens uses painting models erase text different signs backgrounds way translated text placed top clean surfaces using generative models tries predict create pixels match surrounding pixels overread translated text looks natural seamless doesnt always work seamlessly one picking first line im sure translations dont fully account context alto mexican stop sign might mistranslated high optical character recognition frequently identify text bad lighting complicated perspective limits one deformable objects whenever text like sweater cookie wrapper depending pose angle might challenging difficult extract right ocr wellformed grammatically correct fluent text quite good challenges people using slang using casual speech chat social media dont necessarily see much dont access much data google working add features like letting users refine translations want similar ask google gemini chatgbt make translation less formal chilean spanish rather european spanish also working add languages estimated 6000 7000 languages world goal support